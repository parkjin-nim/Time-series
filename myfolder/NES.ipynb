{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Natural Evolution Strategy(NES)\n",
    "- purpose: \n",
    "    - multi-dimensional, real-value(continuous search space), black-box optimization\n",
    "    - 직접 weight를 optimize하지 않고 (weight의)distribution의 parameter를 optimize해\n",
    "      새로운 weight후보를 sampling추출하는 방식\n",
    "\n",
    "- steps: \n",
    "    - 오직 better individual이 되기위한 mutation에 집중됨\n",
    "    - population: 각 individual은 (search) distribution으로부터 sampling됨.\n",
    "    - mutation과정은 **(search) distribution parameter, theta를 update하는 과정임(i.e., Gaussian분포라 가정하면 mu와 cov.)**\n",
    "        - Sample들과 그 fitness값을 이용해 Monte Carlo simulation방식으로, theta에 대한 gradient를 추정.\n",
    "        - gradient를 Natural gradient로 바꿈.\n",
    "        - 높은 기대값의 fitness를 구하는 방향으로 gradient ascent방식으로 theta를 update한다. \n",
    "        - **(search) distribution의 모양을 adaptive방식으로 capture하는 것**\n",
    "       \n",
    "- usage:\n",
    "    - complex function optimization에 사용\n",
    "    - **Natural Gradient를 사용**해 objective에 대한 정보가 없는 경우, continuous, complex, noisy, 시간에 따라 변하는 문제에 적용가능 \n",
    "    - parallel computing, multi-objective, contraint optimization 적용가능\n",
    "    \n",
    "- papaers:\n",
    "    - Natural Evolution Strategies - Daan Wierstra et.al\n",
    "    - Benchmarking Separable Natural Evolution Strategies on the Noiseless and Noisy Black-box Optimization Testbeds - Tom Schaul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0. w: [1.76405235 0.40015721 0.97873798], solution: [ 0.5  0.1 -0.3], reward: -3.323094\n",
      "iter 20. w: [1.63796944 0.36987244 0.84497941], solution: [ 0.5  0.1 -0.3], reward: -2.678783\n",
      "iter 40. w: [1.50042904 0.33577052 0.70329169], solution: [ 0.5  0.1 -0.3], reward: -2.063040\n",
      "iter 60. w: [1.36438269 0.29247833 0.56990397], solution: [ 0.5  0.1 -0.3], reward: -1.540938\n",
      "iter 80. w: [1.2257328  0.25622233 0.43607161], solution: [ 0.5  0.1 -0.3], reward: -1.092895\n",
      "iter 100. w: [1.08819889 0.22827364 0.30415088], solution: [ 0.5  0.1 -0.3], reward: -0.727430\n",
      "iter 120. w: [0.95675286 0.19282042 0.16682465], solution: [ 0.5  0.1 -0.3], reward: -0.435164\n",
      "iter 140. w: [0.82214521 0.16161165 0.03600742], solution: [ 0.5  0.1 -0.3], reward: -0.220475\n",
      "iter 160. w: [ 0.70282088  0.12935569 -0.09779598], solution: [ 0.5  0.1 -0.3], reward: -0.082885\n",
      "iter 180. w: [ 0.58380424  0.11579811 -0.21083135], solution: [ 0.5  0.1 -0.3], reward: -0.015224\n",
      "iter 200. w: [ 0.52089064  0.09897718 -0.2761225 ], solution: [ 0.5  0.1 -0.3], reward: -0.001008\n",
      "iter 220. w: [ 0.50861791  0.10220363 -0.29023563], solution: [ 0.5  0.1 -0.3], reward: -0.000174\n",
      "iter 240. w: [ 0.50428202  0.10834192 -0.29828744], solution: [ 0.5  0.1 -0.3], reward: -0.000091\n",
      "iter 260. w: [ 0.50147991  0.1044559  -0.30255291], solution: [ 0.5  0.1 -0.3], reward: -0.000029\n",
      "iter 280. w: [ 0.50208135  0.0986722  -0.29841024], solution: [ 0.5  0.1 -0.3], reward: -0.000009\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "[코드참고: https://gist.github.com/karpathy/77fbb6a8dac5395f1b73e7a89300318d]\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "A bare bones examples of optimizing a black-box function (f) using\n",
    "Natural Evolution Strategies (NES), where the parameter distribution is a \n",
    "gaussian of fixed standard deviation.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "# the function we want to optimize\n",
    "def f(w):\n",
    "    # here we would normally:\n",
    "    # ... 1) create a neural network with weights w\n",
    "    # ... 2) run the neural network on the environment for some time\n",
    "    # ... 3) sum up and return the total reward\n",
    "\n",
    "    # but for the purposes of an example, lets try to minimize\n",
    "    # the L2 distance to a specific solution vector. So the highest reward\n",
    "    # we can achieve is 0, when the vector w is exactly equal to solution\n",
    "    \n",
    "    reward = -np.sum(np.square(solution - w))\n",
    "    return reward\n",
    "    \n",
    "# hyperparameters\n",
    "npop = 50 # population size\n",
    "sigma = 0.1 # noise standard deviation\n",
    "alpha = 0.001 # learning rate\n",
    "\n",
    "# start the optimization\n",
    "solution = np.array([0.5, 0.1, -0.3])\n",
    "w = np.random.randn(3) # our initial guess is random\n",
    "for i in range(300):\n",
    "\n",
    "    # print current fitness of the most likely parameter setting\n",
    "    if i % 20 == 0:\n",
    "        print('iter %d. w: %s, solution: %s, reward: %f' % \n",
    "          (i, str(w), str(solution), f(w)))\n",
    "\n",
    "    # initialize memory for a population of w's, and their rewards\n",
    "    N = np.random.randn(npop, 3) # samples from a normal distribution N(0,1)\n",
    "    R = np.zeros(npop)\n",
    "    for j in range(npop):\n",
    "        w_try = w + sigma*N[j] # jitter w using gaussian of sigma 0.1\n",
    "        R[j] = f(w_try) # evaluate the jittered version\n",
    "        \n",
    "    # standardize the rewards to have a gaussian distribution\n",
    "    A = (R - np.mean(R)) / np.std(R)\n",
    "    \n",
    "    # perform the parameter update. The matrix multiply below\n",
    "    # is just an efficient way to sum up all the rows of the noise matrix N,\n",
    "    # where each row N[j] is weighted by A[j]\n",
    "    w = w + alpha/(npop*sigma) * np.dot(N.T, A)\n",
    "\n",
    "# when run, prints:\n",
    "# iter 0. w: [ 1.76405235  0.40015721  0.97873798], solution: [ 0.5  0.1 -0.3], reward: -3.323094\n",
    "# iter 20. w: [ 1.63796944  0.36987244  0.84497941], solution: [ 0.5  0.1 -0.3], reward: -2.678783\n",
    "# iter 40. w: [ 1.50042904  0.33577052  0.70329169], solution: [ 0.5  0.1 -0.3], reward: -2.063040\n",
    "# iter 60. w: [ 1.36438269  0.29247833  0.56990397], solution: [ 0.5  0.1 -0.3], reward: -1.540938\n",
    "# iter 80. w: [ 1.2257328   0.25622233  0.43607161], solution: [ 0.5  0.1 -0.3], reward: -1.092895\n",
    "# iter 100. w: [ 1.08819889  0.22827364  0.30415088], solution: [ 0.5  0.1 -0.3], reward: -0.727430\n",
    "# iter 120. w: [ 0.95675286  0.19282042  0.16682465], solution: [ 0.5  0.1 -0.3], reward: -0.435164\n",
    "# iter 140. w: [ 0.82214521  0.16161165  0.03600742], solution: [ 0.5  0.1 -0.3], reward: -0.220475\n",
    "# iter 160. w: [ 0.70282088  0.12935569 -0.09779598], solution: [ 0.5  0.1 -0.3], reward: -0.082885\n",
    "# iter 180. w: [ 0.58380424  0.11579811 -0.21083135], solution: [ 0.5  0.1 -0.3], reward: -0.015224\n",
    "# iter 200. w: [ 0.52089064  0.09897718 -0.2761225 ], solution: [ 0.5  0.1 -0.3], reward: -0.001008\n",
    "# iter 220. w: [ 0.50861791  0.10220363 -0.29023563], solution: [ 0.5  0.1 -0.3], reward: -0.000174\n",
    "# iter 240. w: [ 0.50428202  0.10834192 -0.29828744], solution: [ 0.5  0.1 -0.3], reward: -0.000091\n",
    "# iter 260. w: [ 0.50147991  0.1044559  -0.30255291], solution: [ 0.5  0.1 -0.3], reward: -0.000029\n",
    "# iter 280. w: [ 0.50208135  0.0986722  -0.29841024], solution: [ 0.5  0.1 -0.3], reward: -0.000009\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NES_v2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import *\n",
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal\n",
    "import scipy.stats\n",
    "np.random.seed(0)\n",
    "\n",
    "# the function we want to optimize\n",
    "def fobj_(w):\n",
    "    # take negative. because of NES's only gradient ascent.\n",
    "    reward = -np.sum(np.square(solution - w))\n",
    "    return reward\n",
    "\n",
    "def nes(f, alpha=0.001, sigma=0.1, npop=5000, its=1000):\n",
    "\n",
    "    w = np.random.randn(3) # our initial guess is random\n",
    "\n",
    "    for i in range(its):\n",
    "\n",
    "        # print current fitness of the most likely parameter setting\n",
    "        if i % 20 == 0:\n",
    "            print('iter %d. w: %s, solution: %s, reward: %f' % \n",
    "              (i, str(w), str(solution), f(w)))\n",
    "\n",
    "        # initialize memory for a population of w's, and their rewards\n",
    "        N = np.random.randn(npop, 3) # samples from a normal distribution N(0,1)\n",
    "        R = np.zeros(npop)\n",
    "        for j in range(npop):\n",
    "            w_try = w + sigma*N[j] # jitter w using gaussian of sigma 0.1\n",
    "            R[j] = f(w_try) # evaluate the jittered version\n",
    "\n",
    "        # standardize the rewards to have a gaussian distribution\n",
    "        A = (R - np.mean(R)) / np.std(R)\n",
    "\n",
    "        # perform the parameter update. The matrix multiply below\n",
    "        # is just an efficient way to sum up all the rows of the noise matrix N,\n",
    "        # where each row N[j] is weighted by A[j]\n",
    "        w = w + alpha/(npop*sigma) * np.dot(N.T, A)\n",
    "\n",
    "        yield w, f(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0. w: [0.24609468 1.74473559 0.60329413], solution: [ 0.5  0.1 -0.3], reward: -3.585563\n",
      "iter 20. w: [0.27213483 1.57222097 0.50758051], solution: [ 0.5  0.1 -0.3], reward: -2.871543\n",
      "iter 40. w: [0.29931208 1.39872792 0.41265703], solution: [ 0.5  0.1 -0.3], reward: -2.234850\n",
      "iter 60. w: [0.32627166 1.2251898  0.31752627], solution: [ 0.5  0.1 -0.3], reward: -1.677572\n",
      "iter 80. w: [0.35235917 1.05262693 0.22222417], solution: [ 0.5  0.1 -0.3], reward: -1.202014\n",
      "iter 100. w: [0.3793243  0.88038886 0.12880622], solution: [ 0.5  0.1 -0.3], reward: -0.807444\n",
      "iter 120. w: [0.40585262 0.70880061 0.03416105], solution: [ 0.5  0.1 -0.3], reward: -0.491166\n",
      "iter 140. w: [ 0.4323583   0.53889219 -0.05938014], solution: [ 0.5  0.1 -0.3], reward: -0.255100\n",
      "iter 160. w: [ 0.45744291  0.37265986 -0.15090062], solution: [ 0.5  0.1 -0.3], reward: -0.098385\n",
      "iter 180. w: [ 0.47999527  0.22215866 -0.2333023 ], solution: [ 0.5  0.1 -0.3], reward: -0.019772\n",
      "iter 200. w: [ 0.4950797   0.13062281 -0.28343986], solution: [ 0.5  0.1 -0.3], reward: -0.001236\n",
      "iter 220. w: [ 0.49869667  0.10536182 -0.29783885], solution: [ 0.5  0.1 -0.3], reward: -0.000035\n",
      "iter 240. w: [ 0.49996554  0.10098002 -0.29953166], solution: [ 0.5  0.1 -0.3], reward: -0.000001\n",
      "iter 260. w: [ 0.49959959  0.09977924 -0.2997166 ], solution: [ 0.5  0.1 -0.3], reward: -0.000000\n",
      "iter 280. w: [ 0.50051425  0.10000813 -0.30000875], solution: [ 0.5  0.1 -0.3], reward: -0.000000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc35a028b00>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "solution = np.array([0.5, 0.1, -0.3])\n",
    "\n",
    "result = list(nes(fobj_, alpha= 0.001, sigma= 0.1, its=300))\n",
    "\n",
    "x, f = zip(*result)\n",
    "plt.plot(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
