{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Natural Evolution Strategy(NES)\n",
    "- purpose: \n",
    "    - multi-dimensional, real-value(continuous search space), black-box optimization\n",
    "    - parameterized (search) distribution으로부터 새로운 후보를 sampling추출하는 방식\n",
    "\n",
    "- steps: \n",
    "    - 오직 better individual이 되기위한 mutation에 집중됨\n",
    "    - population: 각 individual은 (search) distribution으로부터 sampling됨.\n",
    "    - mutation과정은 **(search) distribution parameter, theta를 update하는 과정임(i.e., Gaussian분포라 가정하면 mu와 cov.)**\n",
    "        - Sample들과 그 fitness값을 이용해 Monte Carlo simulation방식으로, theta에 대한 gradient를 추정.\n",
    "        - gradient를 Natural gradient로 바꿈.\n",
    "        - 높은 기대값의 fitness를 구하는 방향으로 gradient ascent방식으로 theta를 update한다. \n",
    "        - **(search) distribution의 모양을 adaptive방식으로 capture하는 것**\n",
    "       \n",
    "- usage:\n",
    "    - complex function optimization에 사용\n",
    "    - **Natural Gradient를 사용**해 objective에 대한 정보가 없는 경우, continuous, complex, noisy, 시간에 따라 변하는 문제에 적용가능 \n",
    "    - parallel computing, multi-objective, contraint optimization 적용가능\n",
    "    \n",
    "- papaers:\n",
    "    - Natural Evolution Strategies - Daan Wierstra et.al\n",
    "    - Benchmarking Separable Natural Evolution Strategies on the Noiseless and Noisy Black-box Optimization Testbeds - Tom Schaul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0. w: [1.76405235 0.40015721 0.97873798], solution: [ 0.5  0.1 -0.3], reward: -3.323094\n",
      "iter 20. w: [1.63796944 0.36987244 0.84497941], solution: [ 0.5  0.1 -0.3], reward: -2.678783\n",
      "iter 40. w: [1.50042904 0.33577052 0.70329169], solution: [ 0.5  0.1 -0.3], reward: -2.063040\n",
      "iter 60. w: [1.36438269 0.29247833 0.56990397], solution: [ 0.5  0.1 -0.3], reward: -1.540938\n",
      "iter 80. w: [1.2257328  0.25622233 0.43607161], solution: [ 0.5  0.1 -0.3], reward: -1.092895\n",
      "iter 100. w: [1.08819889 0.22827364 0.30415088], solution: [ 0.5  0.1 -0.3], reward: -0.727430\n",
      "iter 120. w: [0.95675286 0.19282042 0.16682465], solution: [ 0.5  0.1 -0.3], reward: -0.435164\n",
      "iter 140. w: [0.82214521 0.16161165 0.03600742], solution: [ 0.5  0.1 -0.3], reward: -0.220475\n",
      "iter 160. w: [ 0.70282088  0.12935569 -0.09779598], solution: [ 0.5  0.1 -0.3], reward: -0.082885\n",
      "iter 180. w: [ 0.58380424  0.11579811 -0.21083135], solution: [ 0.5  0.1 -0.3], reward: -0.015224\n",
      "iter 200. w: [ 0.52089064  0.09897718 -0.2761225 ], solution: [ 0.5  0.1 -0.3], reward: -0.001008\n",
      "iter 220. w: [ 0.50861791  0.10220363 -0.29023563], solution: [ 0.5  0.1 -0.3], reward: -0.000174\n",
      "iter 240. w: [ 0.50428202  0.10834192 -0.29828744], solution: [ 0.5  0.1 -0.3], reward: -0.000091\n",
      "iter 260. w: [ 0.50147991  0.1044559  -0.30255291], solution: [ 0.5  0.1 -0.3], reward: -0.000029\n",
      "iter 280. w: [ 0.50208135  0.0986722  -0.29841024], solution: [ 0.5  0.1 -0.3], reward: -0.000009\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "[코드참고: https://gist.github.com/karpathy/77fbb6a8dac5395f1b73e7a89300318d]\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "A bare bones examples of optimizing a black-box function (f) using\n",
    "Natural Evolution Strategies (NES), where the parameter distribution is a \n",
    "gaussian of fixed standard deviation.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "# the function we want to optimize\n",
    "def f(w):\n",
    "    # here we would normally:\n",
    "    # ... 1) create a neural network with weights w\n",
    "    # ... 2) run the neural network on the environment for some time\n",
    "    # ... 3) sum up and return the total reward\n",
    "\n",
    "    # but for the purposes of an example, lets try to minimize\n",
    "    # the L2 distance to a specific solution vector. So the highest reward\n",
    "    # we can achieve is 0, when the vector w is exactly equal to solution\n",
    "    \n",
    "    reward = -np.sum(np.square(solution - w))\n",
    "    return reward\n",
    "    \n",
    "    # fitness function is defined as minimizing vector dot product length.  \n",
    "#     value = 0\n",
    "#     for i in range(len(x)):\n",
    "#         value += x[i]**2\n",
    "#     return value / len(x)\n",
    "\n",
    "# hyperparameters\n",
    "npop = 50 # population size\n",
    "sigma = 0.1 # noise standard deviation\n",
    "alpha = 0.001 # learning rate\n",
    "\n",
    "# start the optimization\n",
    "solution = np.array([0.5, 0.1, -0.3])\n",
    "w = np.random.randn(3) # our initial guess is random\n",
    "for i in range(300):\n",
    "\n",
    "    # print current fitness of the most likely parameter setting\n",
    "    if i % 20 == 0:\n",
    "        print('iter %d. w: %s, solution: %s, reward: %f' % \n",
    "          (i, str(w), str(solution), f(w)))\n",
    "\n",
    "    # initialize memory for a population of w's, and their rewards\n",
    "    N = np.random.randn(npop, 3) # samples from a normal distribution N(0,1)\n",
    "    R = np.zeros(npop)\n",
    "    for j in range(npop):\n",
    "        w_try = w + sigma*N[j] # jitter w using gaussian of sigma 0.1\n",
    "        R[j] = f(w_try) # evaluate the jittered version\n",
    "        \n",
    "    # standardize the rewards to have a gaussian distribution\n",
    "    A = (R - np.mean(R)) / np.std(R)\n",
    "    \n",
    "    # perform the parameter update. The matrix multiply below\n",
    "    # is just an efficient way to sum up all the rows of the noise matrix N,\n",
    "    # where each row N[j] is weighted by A[j]\n",
    "    w = w + alpha/(npop*sigma) * np.dot(N.T, A)\n",
    "\n",
    "# when run, prints:\n",
    "# iter 0. w: [ 1.76405235  0.40015721  0.97873798], solution: [ 0.5  0.1 -0.3], reward: -3.323094\n",
    "# iter 20. w: [ 1.63796944  0.36987244  0.84497941], solution: [ 0.5  0.1 -0.3], reward: -2.678783\n",
    "# iter 40. w: [ 1.50042904  0.33577052  0.70329169], solution: [ 0.5  0.1 -0.3], reward: -2.063040\n",
    "# iter 60. w: [ 1.36438269  0.29247833  0.56990397], solution: [ 0.5  0.1 -0.3], reward: -1.540938\n",
    "# iter 80. w: [ 1.2257328   0.25622233  0.43607161], solution: [ 0.5  0.1 -0.3], reward: -1.092895\n",
    "# iter 100. w: [ 1.08819889  0.22827364  0.30415088], solution: [ 0.5  0.1 -0.3], reward: -0.727430\n",
    "# iter 120. w: [ 0.95675286  0.19282042  0.16682465], solution: [ 0.5  0.1 -0.3], reward: -0.435164\n",
    "# iter 140. w: [ 0.82214521  0.16161165  0.03600742], solution: [ 0.5  0.1 -0.3], reward: -0.220475\n",
    "# iter 160. w: [ 0.70282088  0.12935569 -0.09779598], solution: [ 0.5  0.1 -0.3], reward: -0.082885\n",
    "# iter 180. w: [ 0.58380424  0.11579811 -0.21083135], solution: [ 0.5  0.1 -0.3], reward: -0.015224\n",
    "# iter 200. w: [ 0.52089064  0.09897718 -0.2761225 ], solution: [ 0.5  0.1 -0.3], reward: -0.001008\n",
    "# iter 220. w: [ 0.50861791  0.10220363 -0.29023563], solution: [ 0.5  0.1 -0.3], reward: -0.000174\n",
    "# iter 240. w: [ 0.50428202  0.10834192 -0.29828744], solution: [ 0.5  0.1 -0.3], reward: -0.000091\n",
    "# iter 260. w: [ 0.50147991  0.1044559  -0.30255291], solution: [ 0.5  0.1 -0.3], reward: -0.000029\n",
    "# iter 280. w: [ 0.50208135  0.0986722  -0.29841024], solution: [ 0.5  0.1 -0.3], reward: -0.000009\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NES_v2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import *\n",
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal\n",
    "import scipy.stats\n",
    "np.random.seed(0)\n",
    "\n",
    "# the function we want to optimize\n",
    "def fobj_(w):\n",
    "    # take negative. because of NES's only gradient ascent.\n",
    "    reward = -np.sum(np.square(solution - w))\n",
    "    return reward\n",
    "\n",
    "def nes(f, alpha=0.001, sigma=0.1, asigma=0.00001, npop=5000, its=1000):\n",
    "\n",
    "    w = np.random.randn(3) # our initial guess is random\n",
    "    p = np.random.randn(npop, 3)\n",
    "    for i in range(its):\n",
    "\n",
    "        # print current fitness of the most likely parameter setting\n",
    "        if i % 20 == 0:\n",
    "            print('iter %d. w: %s, solution: %s, reward: %f' % \n",
    "              (i, str(w), str(solution), f(w)))\n",
    "\n",
    "        # initialize memory for a population of w's, and their rewards\n",
    "        N = np.random.randn(npop, 3) # samples from a normal distribution N(0,1)\n",
    "        R = np.zeros(npop)\n",
    "        for j in range(npop):\n",
    "            w_try = w + sigma*N[j] # jitter w using gaussian of sigma 0.1\n",
    "            R[j] = f(w_try) # evaluate the jittered version\n",
    "\n",
    "        # standardize the rewards to have a gaussian distribution\n",
    "        A = (R - np.mean(R)) / np.std(R)\n",
    "\n",
    "        # perform the parameter update. The matrix multiply below\n",
    "        # is just an efficient way to sum up all the rows of the noise matrix N,\n",
    "        # where each row N[j] is weighted by A[j]\n",
    "        w = w + alpha/(npop*sigma) * np.dot(N.T, A)\n",
    "\n",
    "        yield w, -f(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0. w: [1.76405235 0.40015721 0.97873798], solution: [ 0.5  0.1 -0.3], reward: -3.323094\n",
      "iter 20. w: [1.62617722 0.36702464 0.83935126], solution: [ 0.5  0.1 -0.3], reward: -2.637699\n",
      "iter 40. w: [1.48768054 0.33382733 0.69890783], solution: [ 0.5  0.1 -0.3], reward: -2.028005\n",
      "iter 60. w: [1.34946005 0.3010699  0.5591144 ], solution: [ 0.5  0.1 -0.3], reward: -1.500089\n",
      "iter 80. w: [1.2116977  0.26682103 0.42001463], solution: [ 0.5  0.1 -0.3], reward: -1.052764\n",
      "iter 100. w: [1.07435785 0.23537741 0.28132655], solution: [ 0.5  0.1 -0.3], reward: -0.686155\n",
      "iter 120. w: [0.93769626 0.20227759 0.14343242], solution: [ 0.5  0.1 -0.3], reward: -0.398671\n",
      "iter 140. w: [0.80229221 0.17084618 0.00618809], solution: [ 0.5  0.1 -0.3], reward: -0.190151\n",
      "iter 160. w: [ 0.67127884  0.14005769 -0.12483044], solution: [ 0.5  0.1 -0.3], reward: -0.061625\n",
      "iter 180. w: [ 0.56271368  0.11380143 -0.23642717], solution: [ 0.5  0.1 -0.3], reward: -0.008165\n",
      "iter 200. w: [ 0.51250428  0.10345247 -0.28633578], solution: [ 0.5  0.1 -0.3], reward: -0.000355\n",
      "iter 220. w: [ 0.50228649  0.10114468 -0.29692082], solution: [ 0.5  0.1 -0.3], reward: -0.000016\n",
      "iter 240. w: [ 0.50105501  0.09912493 -0.2992283 ], solution: [ 0.5  0.1 -0.3], reward: -0.000002\n",
      "iter 260. w: [ 0.50033567  0.09994084 -0.29930528], solution: [ 0.5  0.1 -0.3], reward: -0.000001\n",
      "iter 280. w: [ 0.50053837  0.10033033 -0.29947292], solution: [ 0.5  0.1 -0.3], reward: -0.000001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7feff4b5dcf8>]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "solution = np.array([0.5, 0.1, -0.3])\n",
    "\n",
    "result = list(nes(fobj_, alpha= 0.001, sigma= 0.1, its=300))\n",
    "\n",
    "x, f = zip(*result)\n",
    "plt.plot(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
